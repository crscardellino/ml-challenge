{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(DATA_DIR + \"/meli/train_reliable.parquet\")\n",
    "dev_df = pd.read_parquet(DATA_DIR + \"/meli/dev.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "es_train_df = train_df[train_df.language == \"spanish\"]\n",
    "es_dev_df = dev_df[dev_df.language == \"spanish\"]\n",
    "\n",
    "es_lbl_enc = LabelEncoder().fit(es_train_df.category.tolist() + es_dev_df.category.tolist())\n",
    "es_train_df[\"target\"] = es_lbl_enc.transform(es_train_df.category)\n",
    "es_dev_df[\"target\"] = es_lbl_enc.transform(es_dev_df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pt_train_df = train_df[train_df.language == \"portuguese\"]\n",
    "pt_dev_df = dev_df[dev_df.language == \"portuguese\"]\n",
    "\n",
    "pt_lbl_enc = LabelEncoder().fit(pt_train_df.category.tolist() + pt_dev_df.category.tolist())\n",
    "pt_train_df[\"target\"] = pt_lbl_enc.transform(pt_train_df.category)\n",
    "pt_dev_df[\"target\"] = pt_lbl_enc.transform(pt_dev_df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_w2v = KeyedVectors.load_word2vec_format(DATA_DIR + \"/spanish/spanish-word2vec.bin.gz\", binary=True)\n",
    "pt_w2v = KeyedVectors.load_word2vec_format(DATA_DIR + \"/portuguese/portuguese-word2vec.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_sequence(tokens, token_to_idx, default_value=\"UNK\"):\n",
    "    return [token_to_idx.get(token, token_to_idx[default_value]) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LEN = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = pd.concat([es_train_df.words, es_dev_df.words])\n",
    "\n",
    "es_word_index = {word for words in all_words for word in words if word in es_w2v}\n",
    "es_word_index = {word: idx for idx, word in enumerate(sorted(es_word_index), start=1)}\n",
    "es_index_word = {idx: word for idx, word in es_word_index.items()}\n",
    "es_word_index[\"NULL\"] = 0\n",
    "es_index_word[0] = \"NULL\"\n",
    "\n",
    "es_word_index[\"UNK\"] = len(es_word_index)\n",
    "es_index_word[len(es_index_word)] = \"UNK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_token_sequences = tf.keras.preprocessing.sequence.pad_sequences(es_train_df[\"words\"].apply(\n",
    "    lambda words: tokens_to_sequence(words, es_word_index)\n",
    ").tolist(), maxlen=MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_dev_token_sequences = tf.keras.preprocessing.sequence.pad_sequences(es_dev_df[\"words\"].apply(\n",
    "    lambda words: tokens_to_sequence(words, es_word_index)\n",
    ").tolist(), maxlen=MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_target = tf.keras.utils.to_categorical(es_train_df.target.tolist(),\n",
    "                                                num_classes=es_lbl_enc.classes_.shape[0])\n",
    "\n",
    "es_dev_target = tf.keras.utils.to_categorical(es_dev_df.target.tolist(),\n",
    "                                                num_classes=es_lbl_enc.classes_.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(es_word_index), es_w2v.vector_size))\n",
    "\n",
    "for word, i in es_word_index.items():\n",
    "    if word in es_w2v and word not in {\"NULL\", \"UNK\"}:\n",
    "        embedding_matrix[i] = es_w2v[word]\n",
    "    if word == \"UNK\":\n",
    "        np.random.seed(42)\n",
    "        embedding_matrix[i] = np.random.normal(size=(es_w2v.vector_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(len(es_word_index),\n",
    "                                            es_w2v.vector_size,\n",
    "                                            weights=[embedding_matrix],\n",
    "                                            input_length=MAX_SEQUENCE_LEN,\n",
    "                                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LEN,))\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 15, 300)           16699500  \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 14, 128)           76928     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1571)              202659    \n",
      "=================================================================\n",
      "Total params: 16,995,599\n",
      "Trainable params: 296,099\n",
      "Non-trainable params: 16,699,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer = tf.keras.layers.Conv1D(128, 2, activation=\"relu\")(embedded_sequences)\n",
    "layer = tf.keras.layers.MaxPooling1D(2)(layer)\n",
    "layer = tf.keras.layers.Conv1D(128, 2, activation=\"relu\")(embedded_sequences)\n",
    "layer = tf.keras.layers.MaxPooling1D(2)(layer)\n",
    "layer = tf.keras.layers.Conv1D(128, 2, activation=\"relu\")(embedded_sequences)\n",
    "layer = tf.keras.layers.GlobalMaxPooling1D()(layer)\n",
    "layer = tf.keras.layers.Dense(128, activation=\"relu\")(layer)\n",
    "preds = tf.keras.layers.Dense(es_lbl_enc.classes_.shape[0], activation=\"softmax\")(layer)\n",
    "model = tf.keras.models.Model(sequence_input, preds)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 15, 300)      16699500    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 14, 128)      76928       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 13, 128)      115328      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 12, 128)      153728      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 128)          0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 128)          0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 128)          0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 384)          0           global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1571)         604835      concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 17,650,319\n",
      "Trainable params: 950,819\n",
      "Non-trainable params: 16,699,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer1 = tf.keras.layers.Conv1D(128, 2, activation=\"relu\",\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01))(embedded_sequences)\n",
    "layer1 = tf.keras.layers.GlobalMaxPooling1D()(layer1)\n",
    "\n",
    "layer2 = tf.keras.layers.Conv1D(128, 3, activation=\"relu\",\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01))(embedded_sequences)\n",
    "layer2 = tf.keras.layers.GlobalMaxPooling1D()(layer2)\n",
    "\n",
    "layer3 = tf.keras.layers.Conv1D(128, 4, activation=\"relu\",\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01))(embedded_sequences)\n",
    "layer3 = tf.keras.layers.GlobalMaxPooling1D()(layer3)\n",
    "\n",
    "layer = tf.keras.layers.Concatenate()([layer1, layer2, layer3])\n",
    "\n",
    "preds = tf.keras.layers.Dense(es_lbl_enc.classes_.shape[0], activation=\"softmax\")(layer)\n",
    "model = tf.keras.models.Model(sequence_input, preds)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Flatten()(embedded_sequences)\n",
    "layer = tf.keras.layers.Dense(1024, activation=\"relu\")(layer)\n",
    "layer = tf.keras.layers.Dropout(0.3)(layer)\n",
    "layer = tf.keras.layers.Dense(1024, activation=\"relu\")(layer)\n",
    "layer = tf.keras.layers.Dropout(0.3)(layer)\n",
    "preds = tf.keras.layers.Dense(es_lbl_enc.classes_.shape[0], activation=\"softmax\")(layer)\n",
    "model = tf.keras.models.Model(sequence_input, preds)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 466611 samples, validate on 499625 samples\n",
      "Epoch 1/10\n",
      "466611/466611 [==============================] - 40s 86us/sample - loss: 4.7098 - accuracy: 0.3632\n",
      "Epoch 2/10\n",
      "466611/466611 [==============================] - 38s 81us/sample - loss: 2.8123 - accuracy: 0.6264\n",
      "Epoch 3/10\n",
      "466611/466611 [==============================] - 36s 78us/sample - loss: 2.3233 - accuracy: 0.6906\n",
      "Epoch 4/10\n",
      "466611/466611 [==============================] - 38s 81us/sample - loss: 2.0558 - accuracy: 0.7243\n",
      "Epoch 5/10\n",
      "466611/466611 [==============================] - 67s 144us/sample - loss: 1.8795 - accuracy: 0.7460 - val_loss: 6.8131 - val_accuracy: 0.3012\n",
      "Epoch 6/10\n",
      "466611/466611 [==============================] - 36s 78us/sample - loss: 1.7463 - accuracy: 0.7621\n",
      "Epoch 7/10\n",
      "466611/466611 [==============================] - 37s 79us/sample - loss: 1.6475 - accuracy: 0.7735\n",
      "Epoch 8/10\n",
      "466611/466611 [==============================] - 37s 79us/sample - loss: 1.5628 - accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "466611/466611 [==============================] - 37s 79us/sample - loss: 1.4939 - accuracy: 0.7917\n",
      "Epoch 10/10\n",
      "466611/466611 [==============================] - 37s 79us/sample - loss: 1.4361 - accuracy: 0.7983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c2a6ecf98>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(es_train_token_sequences, es_train_target, \n",
    "          validation_data=(es_dev_token_sequences, es_dev_target),\n",
    "          validation_freq=[5], epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 466611 samples, validate on 499625 samples\n",
      "Epoch 1/10\n",
      "466611/466611 [==============================] - 43s 92us/sample - loss: 4.5331 - accuracy: 0.3905\n",
      "Epoch 2/10\n",
      "466611/466611 [==============================] - 43s 93us/sample - loss: 2.6645 - accuracy: 0.6485\n",
      "Epoch 3/10\n",
      "466611/466611 [==============================] - 38s 81us/sample - loss: 2.2113 - accuracy: 0.7065\n",
      "Epoch 4/10\n",
      "466611/466611 [==============================] - 36s 78us/sample - loss: 1.9693 - accuracy: 0.7368\n",
      "Epoch 5/10\n",
      "466611/466611 [==============================] - 64s 137us/sample - loss: 1.8091 - accuracy: 0.7552 - val_loss: 6.5900 - val_accuracy: 0.3114\n",
      "Epoch 6/10\n",
      "466611/466611 [==============================] - 36s 77us/sample - loss: 1.6965 - accuracy: 0.7683\n",
      "Epoch 7/10\n",
      "466611/466611 [==============================] - 40s 86us/sample - loss: 1.6069 - accuracy: 0.7789\n",
      "Epoch 8/10\n",
      "466611/466611 [==============================] - 38s 82us/sample - loss: 1.5352 - accuracy: 0.7873\n",
      "Epoch 9/10\n",
      "466611/466611 [==============================] - 44s 95us/sample - loss: 1.4738 - accuracy: 0.7942\n",
      "Epoch 10/10\n",
      "466611/466611 [==============================] - 43s 93us/sample - loss: 1.4217 - accuracy: 0.8004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d53d217b8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(es_train_token_sequences, es_train_target, \n",
    "          validation_data=(es_dev_token_sequences, es_dev_target),\n",
    "          validation_freq=[5], epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_preds = model.predict(es_train_token_sequences, batch_size=1024, verbose=0)\n",
    "es_dev_preds = model.predict(es_dev_token_sequences, batch_size=1024, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "es_train_df[\"predictions\"] = es_train_preds.argmax(axis=1)\n",
    "es_dev_df[\"predictions\"] = es_dev_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9653978780061945\n",
      "0.3639198812381765\n"
     ]
    }
   ],
   "source": [
    "print(balanced_accuracy_score(es_train_df.target, es_train_df.predictions))\n",
    "print(balanced_accuracy_score(es_dev_df.target, es_dev_df.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7703692876333945"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(es_dev_df[es_dev_df.label_quality==\"reliable\"].target,\n",
    "                        es_dev_df[es_dev_df.label_quality==\"reliable\"].predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
