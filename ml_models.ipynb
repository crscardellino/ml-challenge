{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>split</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Projeto Unidade Hidraulica 3000 Psi</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>[projeto, unidade, hidraulica, 3000, psi]</td>\n",
       "      <td>[NOUN, NOUN, ADJ, NUM, NOUN]</td>\n",
       "      <td>train</td>\n",
       "      <td>AIR_COMPRESSORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tapete Capacho 120x60 Churrasqueira + Frete Gr...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>[tapete, capacho, 120x60, churrasqueira, +, fr...</td>\n",
       "      <td>[NOUN, VERB, NUM, ADJ, PROPN, ADJ, ADJ]</td>\n",
       "      <td>train</td>\n",
       "      <td>CARPETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Camiseta Raglan Crepúsculo Jealous Baby Look</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>[camiseta, raglan, crepúsculo, jealous, baby, ...</td>\n",
       "      <td>[VERB, VERB, ADJ, NOUN, ADJ, NOUN]</td>\n",
       "      <td>train</td>\n",
       "      <td>T_SHIRTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Unidade De Dvd Gravador Com Defeito Apenas Par...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>[unidade, de, dvd, gravador, com, defeito, ape...</td>\n",
       "      <td>[NOUN, ADP, ADJ, NOUN, ADP, NOUN, ADV, ADP, NOUN]</td>\n",
       "      <td>train</td>\n",
       "      <td>DVD_RECORDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fan  Dell R320 / R420 0hr6c0 - 24h</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>[fan, dell, r320, /, r420, 0hr6c0, -, 24h]</td>\n",
       "      <td>[ADV, VERB, NOUN, PUNCT, NOUN, NUM, PUNCT, NOUN]</td>\n",
       "      <td>train</td>\n",
       "      <td>DESKTOP_COMPUTER_COOLERS_AND_FANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title label_quality  \\\n",
       "16                Projeto Unidade Hidraulica 3000 Psi      reliable   \n",
       "25  Tapete Capacho 120x60 Churrasqueira + Frete Gr...      reliable   \n",
       "57       Camiseta Raglan Crepúsculo Jealous Baby Look      reliable   \n",
       "82  Unidade De Dvd Gravador Com Defeito Apenas Par...      reliable   \n",
       "99                 Fan  Dell R320 / R420 0hr6c0 - 24h      reliable   \n",
       "\n",
       "      language                                              words  \\\n",
       "16  portuguese          [projeto, unidade, hidraulica, 3000, psi]   \n",
       "25  portuguese  [tapete, capacho, 120x60, churrasqueira, +, fr...   \n",
       "57  portuguese  [camiseta, raglan, crepúsculo, jealous, baby, ...   \n",
       "82  portuguese  [unidade, de, dvd, gravador, com, defeito, ape...   \n",
       "99  portuguese         [fan, dell, r320, /, r420, 0hr6c0, -, 24h]   \n",
       "\n",
       "                                                  pos  split  \\\n",
       "16                       [NOUN, NOUN, ADJ, NUM, NOUN]  train   \n",
       "25            [NOUN, VERB, NUM, ADJ, PROPN, ADJ, ADJ]  train   \n",
       "57                 [VERB, VERB, ADJ, NOUN, ADJ, NOUN]  train   \n",
       "82  [NOUN, ADP, ADJ, NOUN, ADP, NOUN, ADV, ADP, NOUN]  train   \n",
       "99   [ADV, VERB, NOUN, PUNCT, NOUN, NUM, PUNCT, NOUN]  train   \n",
       "\n",
       "                             category  \n",
       "16                    AIR_COMPRESSORS  \n",
       "25                            CARPETS  \n",
       "57                           T_SHIRTS  \n",
       "82                      DVD_RECORDERS  \n",
       "99  DESKTOP_COMPUTER_COOLERS_AND_FANS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(DATA_DIR + \"/meli/train_reliable.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"normalized_title\"] = train_df[\"words\"].apply(lambda words: \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/ccardellino/.local/conda/envs/nlu/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                       fit_intercept=True, intercept_scaling=1,\n",
       "                                       loss='squared_hinge', max_iter=1000,\n",
       "                                       multi_class='ovr', penalty='l2',\n",
       "                                       random_state=None, tol=0.0001,\n",
       "                                       verbose=0),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [2.0, 1.0, 0.5, 0.25],\n",
       "                                        'class_weight': [None, 'balanced'],\n",
       "                                        'dual': [True],\n",
       "                                        'loss': ['hinge', 'squared_hinge'],\n",
       "                                        'max_iter': [500, 1000, 1500, 2000],\n",
       "                                        'random_state': [42]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='balanced_accuracy',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"dual\": [True],\n",
    "    \"C\": [2.0, 1.0, 0.5, 0.25],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"max_iter\": [500, 1000, 1500, 2000],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(LinearSVC(), param_grid, n_iter=10, scoring=\"balanced_accuracy\")\n",
    "search.fit(iris[\"data\"], iris[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[(train_df.split == \"train\") & (train_df.label_quality == \"unreliable\")].to_parquet(\n",
    "    DATA_DIR + \"/meli/train_unreliable.parquet\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(DATA_DIR + \"/meli/train_reliable.parquet\")\n",
    "dev_df = pd.read_parquet(DATA_DIR + \"/meli/dev.parquet\")\n",
    "\n",
    "test_df = pd.read_parquet(DATA_DIR + \"/meli/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = LabelEncoder()\n",
    "dev_df[\"target\"] = lbl_enc.fit_transform(dev_df.category)\n",
    "train_df[\"target\"] = lbl_enc.transform(train_df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_df = train_df[train_df.language == \"spanish\"]\n",
    "pt_train_df = train_df[train_df.language == \"portuguese\"]\n",
    "\n",
    "es_dev_df = dev_df[dev_df.language == \"spanish\"]\n",
    "pt_dev_df = dev_df[dev_df.language == \"portuguese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_test_df = test_df[test_df.language == \"spanish\"]\n",
    "pt_test_df = test_df[test_df.language == \"portuguese\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_sw = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "def token_extractor(tokens):\n",
    "    return tokens.tolist()\n",
    "\n",
    "es_count = CountVectorizer(strip_accents=\"unicode\", min_df=2,\n",
    "                           analyzer=token_extractor, ngram_range=(1, 2),\n",
    "                           max_features=30000)\n",
    "es_count.fit(list(es_train_df.words) + list(es_dev_df.words))\n",
    "es_train_cv = es_count.transform(es_train_df.words)\n",
    "es_dev_cv = es_count.transform(es_dev_df.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "es_clf = SGDClassifier(loss=\"hinge\", verbose=0, random_state=42, n_jobs=-1, max_iter=1500)\n",
    "es_clf.fit(es_train_cv, es_train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_df[\"predictions\"] = es_clf.predict(es_train_cv)\n",
    "es_dev_df[\"predictions\"] = es_clf.predict(es_dev_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(balanced_accuracy_score(es_train_df.target, es_train_df.predictions))\n",
    "print(balanced_accuracy_score(es_dev_df.target, es_dev_df.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(es_dev_df[es_dev_df.label_quality==\"reliable\"].target,\n",
    "                        es_dev_df[es_dev_df.label_quality==\"reliable\"].predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_test_cv = es_count.transform(es_test_df.words)\n",
    "es_test_df[\"predictions\"] = es_clf.predict(es_test_cv)\n",
    "es_test_df[\"category\"] = lbl_enc.inverse_transform(es_test_df.predictions)\n",
    "es_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sw = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "def token_extractor(tokens):\n",
    "    return tokens.tolist()\n",
    "\n",
    "pt_count = CountVectorizer(strip_accents=\"unicode\", min_df=2,\n",
    "                           analyzer=token_extractor, ngram_range=(1, 2),\n",
    "                           max_features=20000)\n",
    "pt_count.fit(list(pt_train_df.words) + list(pt_dev_df.words))\n",
    "pt_train_cv = pt_count.transform(pt_train_df.words)\n",
    "pt_dev_cv = pt_count.transform(pt_dev_df.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pt_clf = LinearSVC(verbose=10, random_state=42)\n",
    "pt_clf.fit(pt_train_cv, pt_train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_train_df[\"predictions\"] = pt_clf.predict(pt_train_cv)\n",
    "pt_dev_df[\"predictions\"] = pt_clf.predict(pt_dev_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(balanced_accuracy_score(pt_train_df.target, pt_train_df.predictions))\n",
    "print(balanced_accuracy_score(pt_dev_df.target, pt_dev_df.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(pt_dev_df[pt_dev_df.label_quality==\"reliable\"].target,\n",
    "                        pt_dev_df[pt_dev_df.label_quality==\"reliable\"].predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_test_cv = pt_count.transform(pt_test_df.words)\n",
    "pt_test_df[\"predictions\"] = pt_clf.predict(pt_test_cv)\n",
    "pt_test_df[\"category\"] = lbl_enc.inverse_transform(pt_test_df.predictions)\n",
    "pt_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([es_test_df, pt_test_df])[[\"id\", \"title\", \"category\"]].sort_values(\"id\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[[\"id\", \"category\"]].to_csv(DATA_DIR + \"/meli/submission_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
